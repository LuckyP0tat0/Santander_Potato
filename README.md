# Santander_Potato
Моё решение кагловского соревнования



# Santander Customer Transaction Prediction

## Итоги работы

В рамках решения задачи я последовательно протестировал несколько подходов — от базовых моделей до ансамблей и более продвинутых техник.

---

## 1. Базовые модели

### Линейная модель

Логистическая регрессия показала стабильный и неплохой результат на кросс-валидации. Это дало хороший базовый ориентир качества.

### LightGBM

Первая версия была реализована некорректно и показала низкий скор (~0.6). После исправления пайплайна и параметров модель вышла на ~0.89 AUC и стала сильным бейзлайном среди деревьев.

---

## 2. CatBoost и улучшения

### Базовый CatBoost

CatBoost показал качество на уровне LightGBM (~0.89), но оказался более стабильным, а также быстрее обучался на gpu.

### Feature-wise augmentation

Я добавил аугментацию признаков: внутри каждого класса генерировались синтетические объекты путём случайного перемешивания значений признаков.
Это снизило variance и немного улучшило OOF.

### Seed Ensemble

Для каждого фолда обучалось несколько моделей с разными random_seed, после чего их предсказания усреднялись.
Это дополнительно стабилизировало модель.

---

## 3. PCA и ансамбли

Я попробовал добавить PCA-компоненты к CatBoost.
Это немного улучшило чистый CatBoost, но уступило финальному ансамблю.

Далее был реализован линейный бленд:

* CatBoost
* LightGBM
* CatBoost + PCA

Подбор оптимальных весов проводился по OOF AUC.
Итоговый ансамбль позволил получить скор около 0.90.

---

## 4. Абьюз утечки

В конце я протестировал известный трюк с утечкой через частоты значений:

* Для каждого признака были посчитаны `value_counts` по объединению train и test.
* Частота значения добавлялась как дополнительная фича.
* Для каждого признака обучалась отдельная модель.
* Логиты моделей суммировались.

Этот подход использует информацию о распределении теста и является формой data leakage.
Он резко повысил скор до ~0.92.

---

## 5. Итоговые результаты

| Подход               | Private AUC |
| -------------------- | ----------- |
| Линейная модель      | ~0.88       |
| LightGBM             | ~0.89       |
| CatBoost + улучшения | ~0.90       |
| Абьюз утечки         | ~0.92       |

В итоге я получил результат уровня топ-процентов исторического лидерборда, а также разобрался с ансамблями, бустингом и влиянием утечек данных на итоговый скор.

